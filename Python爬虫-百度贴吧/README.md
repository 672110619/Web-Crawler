#项目分析
----

**项目内容：**
用Python写的百度贴吧的网络爬虫。

**程序功能：**
将贴吧中楼主发布的内容打包txt存储到本地。

**原理解释：**
首先，先浏览一下某一条贴吧，点击只看楼主并点击第二页之后url发生了一点变化，变成了：
http://tieba.baidu.com/p/2296712428?see_lz=1&pn=1
可以看出来，see_lz=1是只看楼主，pn=1是对应的页码，记住这一点为以后的编写做准备。
这就是我们需要利用的url。

**代码分析：**

 1. 4-6：没有这几行代码就会出现`'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)`的错误

 2. 8：刚开始得到的数据还有一大片换行符和图片符，好口怕！既然这样，我们就要对这些文本进行处理，把各种各样复杂的标签给它剔除掉，还原精华内容，把文本处理写成一个方法也可以，不过为了实现更好的代码架构和代码重用，我们可以考虑把标签等的处理写作一个类。
 
       那我们就叫它Tool（工具类吧），里面定义了一个方法，叫replace，是替换各种标签的。在类中定义了几个正则表达式，主要利用了re.sub方法对文本进行匹配后然后替换。

       要好好体会这些代码
 
